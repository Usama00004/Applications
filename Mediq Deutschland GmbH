\documentclass[letter,11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{TLCresume}

%====================
% CONTACT INFORMATION
%====================
\def\name{Usama Tahir} 
\def\phone{+4917684973934}
\def\city{Germany}
\def\email{usamatahir00004@gmail.com}
\def\LinkedIn{usamatahir-00004} 
\def\github{Usama00004} 
\def\role{Data Engineer}

\input{_header}

\begin{document}

\section{Summary}  
Detail-oriented Data Engineer with hands-on experience in ETL, data integration, and scalable architecture design. Skilled in Python, SQL, and Power BI, with a proven ability to build data pipelines, automate processes, and deliver actionable insights through BI dashboards. Experienced in working across technical and business teams to support data-driven decision-making.

\section{Skills}  
\textbf{Technical Skills:} Python, Pandas, NumPy, SQL, Power BI, Snowflake, AWS S3, Selenium, AirFlow, Git, Excel, DAX  \\  
\textbf{Data Engineering & BI Tools:} ETL Processes, Data Integration, Data Modeling, Data Visualization, CRM Data Flows, Snowpipe, Kafka, Data Pipelines  \\  
\textbf{Soft Skills:} Communication, Analytical Thinking, Problem Solving, Stakeholder Collaboration, Adaptability, Time Management  \\  
\textbf{Languages:} German (B1 CEFR), English (C1 CEFR), Urdu, Punjabi, Hindi  

\section{Education}  
{\bf Master of Global Software Development}, Hochschule Fulda \hfill {Sept 2026 (expected)} \\  
{\bf Bachelor of Computer Science}, COMSATS Lahore \hfill {2016 - 2020}  

\section{Professional Experience}  

\textbf{Working Student – Data Analyst} \hfill Mar 2025 – Present \\  
Siemens Healthineers \hfill \textit{Forchheim, Germany}  
\begin{itemize}  
    \item Integrated and transformed large, heterogeneous datasets from internal and external sources for analytics and reporting.  
    \item Designed and maintained scalable data warehousing and streaming architectures using Kafka and Snowflake.  
    \item Built SQL-based data models and ETL pipelines ensuring high data availability and performance.  
    \item Supported internal stakeholders by delivering data insights via automated dashboards and ad-hoc reporting.  
\end{itemize}  

\textbf{Junior Data Analyst} \hfill Jan 2021 – July 2022 \\  
Systems Limited \hfill \textit{Lahore, Pakistan}  
\begin{itemize}  
    \item Extracted, cleaned, and consolidated data from CRM systems and external APIs to support business reporting.  
    \item Automated ETL workflows using Python (BeautifulSoup, Selenium), improving processing time and accuracy.  
    \item Developed BI dashboards with Power BI to support strategic and operational decision-making.  
    \item Conducted data quality assessments and collaborated with business teams to refine requirements and ensure data alignment.  
\end{itemize}  

\section{Projects}  

\textbf{Real Estate Data Pipeline Project:} Built an end-to-end data pipeline to process real estate data from Redfin, showcasing modern data engineering practices (available on \href{https://github.com/Usama00004/StreamAnalysis}{GitHub}). Extracted raw data and stored it in AWS S3 for further processing. The datasets were transformed and cleaned to ensure they were analysis-ready. Used Snowpipe to load the transformed data into Snowflake and connected Snowflake to Power BI to deliver actionable visualizations.




\textbf{Data Analysis Dashboard:} Developed a Power BI dashboard to visualize trends and insights from processed data using Python (Pandas). Reduced data processing time by 20\% through preprocessing and error handling pipelines (available on \href{https://github.com/Usama00004/SalesReport}{GitHub}).  

\textbf{Real Estate Data Pipeline Project:} This project demonstrates an ETL (Extract, Transform, Load) pipeline that fetches weather data from an API, processes the data using Python Pandas, and loads the transformed data into a Snowflake table. The data in Snowflake is further used in Power BI to create actionable visualizations and analyses, showcasing end-to-end data engineering practices (available on \href{https://github.com/Usama00004/StreamAnalysis}{GitHub}).

\textbf{Sentiment Analysis Pipeline:} Automated web scraping and sentiment analysis using BeautifulSoup, Selenium, and Scikit-learn. Enhanced efficiency by 25\% and reduced manual effort by 40\% through automation (available on \href{https://github.com/Usama00004/Twitter-Sentiment-Analysis}{GitHub}).  

\section{Publications}  

\textbf{Hotspot-Aware Workload Scheduling and Server Placement for Heterogeneous Cloud Data Centers:} Published in MDPI Energies Journal, this research proposes algorithms for optimizing resource utilization and minimizing energy consumption in cloud environments (see publication on \href{https://www.mdpi.com/1996-1073/15/7/2541}{MDPI Energies}).  


\section{Certifications}  
\begin{itemize}
    \item \textbf{German Language B2.2:} Certified in German B2.2, demonstrating advanced skills for professional communication in German-speaking settings (\href{https://usama-tahir-00004.github.io/portfolio/files/B2_2.pdf}{view certificate}).
    \item \textbf{Microsoft Power BI:} Certified in Power BI, with expertise in transforming data into impactful visual insights (\href{https://github.com/Usama00004/Certifications/blob/main/Microsoft%20Pl-300%20Certified-.pdf}{view certificate}).
    \item \textbf{German Language B1:} Certified in German B1, showcasing intermediate proficiency in understanding and speaking German (\href{https://github.com/Usama00004/Certifications/blob/main/German%20B1%20Certificate.pdf}{view certificate}).
    \item \textbf{Google Data Analytics:} Certified in Google Data Analytics, with skills in analyzing and deriving insights from data ( \href{https://github.com/Usama00004/Certifications/blob/main/Google_Data_Analystics.pdf}{view certificate}).
    \item \textbf{Microsoft Azure:} Certified in Azure Fundamentals, with a solid understanding of cloud computing and Microsoft Azure services ( \href{https://github.com/Usama00004/Certifications/blob/main/AZ-900%20Certified.pdf}{view certificate}).
    \item \textbf{IBM Datastage:} Certified in IBM Datastage, skilled in efficient data integration and management using ETL tools (\href{https://github.com/Usama00004/Certifications/blob/main/IBM%20datastage%20certificate.pdf}{view certificate}).
\end{itemize}

\end{document}




cover letter 


Mediq Deutschland GmbH In d. Bruchwies 10
66663, Merzig
Appkication for the position of (Junior) Data Engineer (m/w/d)
Dear Hiring Team,
Usama Tahir HedderichstraSSe 47A 60594, Frankfurt am Main
June 18, 2025
I am excited to apply for the Data Engineer position at your organization. With a strong academic foundation in Computer Science and currently pursuing a Masters in Global Software Development at Hochschule Fulda, I bring hands-on experience in ETL processes, data integration, and business intelligence solutions that align well with the responsibilities of this role.
In my role as a Working Student Data Analyst at Siemens Healthineers, I designed and maintained scalable data pipelines and warehousing solutions using Snowflake and SQL, while integrating streaming data with Kafka for real-time insights. Previously at Systems Limited, I automated ETL workflows using Python and built Power BI dashboards to support decision-making across depart- ments. These experiences have equipped me to handle complex data from multiple sources, ensure data quality, and enable structured reporting through visualization tools.
I have also worked with CRM system data flows, ensuring data consistency and integration across platforms. My technical skills include Python, SQL, Power BI, Snowflake, and Airflow, and I am comfortable collaborating with both technical and non-technical stakeholders to deliver value through data.
What excites me most about this opportunity is the chance to contribute to a data-driven culture by optimizing processes and developing scalable solutions that impact real business outcomes. I am confident my analytical mindset, communication skills, and hands-on experience make me a strong fit for this position.
Thank you for considering my application. I would welcome the opportunity to further discuss how I can contribute to your data engineering team.
Thanks and Regards
Usama Tahir
(+49)-176-84973934 usamatahir00004@gmail.com https://usama00004.github.io/portfolio/







