\documentclass[11pt,a4paper]{article}

%%%% Include Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[empty]{fullpage}
\usepackage[hidelinks]{hyperref}
\usepackage{xcolor}
\usepackage{ragged2e}
\usepackage{geometry}
\usepackage{setspace}
\usepackage{mathpazo} % Palatino font for a professional look

%%%% Set Margins
\geometry{top=1in, bottom=1in, left=0.8in, right=0.8in}

%%%% Define Colors
\definecolor{UI_blue}{RGB}{32, 64, 151}

%%%% Document Content
\begin{document}

\vspace{1cm} % Space between header and addresses

% Sender and recipient addresses
\noindent
\begin{minipage}[t]{0.45\textwidth}
    ABACUS MEDICINE Berlin GmbH\\
    Mansfelder Str 56 \\
    10709 Berlin\\
    Germany\\

\end{minipage}%
\hfill
\begin{minipage}[t]{0.45\textwidth}
    \raggedleft


    Usama Tahir \\
    Hardenbergerg str 34 \\
    10623 Berlin\\
    Germany\\

    \vspace{1cm} % Adjust the space as needed
    \today
\end{minipage}

\vspace{1cm} % Space between addresses and subject line

% Subject line
\noindent
\textbf{Application for BI Developer Position}

\vspace{0.2cm} % Space between subject line and main content

% Main letter content
\justify
\setlength{\parindent}{0pt}
\setlength{\parskip}{12pt}

Dear Hiring Team,

I am writing to express my interest in the BI Developer position at your organization. With a solid foundation in Data / business analytics, I bring over 2 years of hands-on experience in data analysis, BI development, and dashboard creation using tools like Power BI, SQL, and Python. My academic background in Computer Science and current professional focus align closely with your requirements for a data-driven, collaborative, and results-oriented analyst.

During my time at Siemens Healthineers and Robert Bosch, I contributed to designing scalable data models and building insightful dashboards that supported key business decisions. I streamlined data pipelines using Azure Data Factory and Databricks, improving data refresh times by over 25\% and ensuring data accuracy through automated validation checks. These experiences have equipped me to work confidently across modern data infrastructure and to deliver reliable, high-impact BI solutions.

Your emphasis on storytelling through dashboards, data governance, and innovation strongly resonates with my own approach to analytics. I take pride in translating complex data into clear, actionable insights and collaborating across departments to align technical outcomes with business needs.

I would welcome the opportunity to bring my skills and passion for data to your team and contribute to driving data-informed decisions. Thank you for considering my application. I look forward to the possibility of discussing how I can add value to your organization.



\vspace{0.5cm}

Thanks and Regards\\
Usama Tahir \\ 
(+49)-176-84973934 \\ 
\href{mailto:usamatahir00004@gmail.com}{usamatahir00004@gmail.com}\\ 
\href{https://usama00004.github.io/portfolio/}{https://usama00004.github.io/portfolio/}

\end{document}




----


\documentclass{resume} % Use the custom resume.cls style

\usepackage[left=0.4 in,top=0.4in,right=0.4 in,bottom=0.4in]{geometry} % Document margins
\newcommand{\tab}[1]{\hspace{.2667\textwidth}\rlap{#1}} 
\newcommand{\itab}[1]{\hspace{0em}\rlap{#1}}
\name{Usama Tahir} % Add your full name here
\address{+49 17684973934 \\  Germany}
\address{\href{mailto:usamatahir00004@gmail.com}{Email} \\ \href{http://www.linkedin.com/in/usamatahir-00004}{Linked In} \\ 
\href{https://github.com/Usama00004}{Git}} 

\begin{document}

%----------------------------------------------------------------------------------------
%	OBJECTIVE
%----------------------------------------------------------------------------------------

\begin{rSection}{OBJECTIVE}

Detail-oriented Software Engineer transitioning into Data Analytics with experience in data analysis, visualization, and scalable data modeling. Proficient in Power BI, SQL, and Python. Skilled in building business-focused dashboards and translating data into actionable insights. Familiar with Databricks, Azure, AWS, and Azure Data Factory.
\end{rSection}

%----------------------------------------------------------------------------------------
%	EDUCATION SECTION
%----------------------------------------------------------------------------------------

\begin{rSection}{Education}

{\bf Master of Global Software Development}, Hochschule Fulda \hfill {Fulda, Germany}\\
{\bf Bachelor of Computer Science}, COMSATS Lahore \hfill {Lahore, Pakistan}

\end{rSection}

%----------------------------------------------------------------------------------------
% TECHNICAL STRENGTHS
%----------------------------------------------------------------------------------------

\begin{rSection}{Skills}

\textbf{Technical Skills:} Power BI, Databricks, Data Factory, Dataflow Gen 2, Data pipelines, Pyspark ,Python, Pandas, NumPy, SQL, Git, Microsoft Office, Share point \\
\textbf{Soft Skills:} Communication, Problem Solving, Adaptability, Time Management \\
\textbf{Languages:} German (B2 CEFR), English (C1 CEFR), Urdu, Punjabi, Hindi 

\end{rSection}

%----------------------------------------------------------------------------------------
%	EXPERIENCE
%----------------------------------------------------------------------------------------

\begin{rSection}{EXPERIENCE}

\textbf{Data Analytics Intern} \hfill July 2025 -- Present\\
Robert Bosch  \hfill \textit{Reutlingen, Germany}
\begin{itemize}
    \item Designed and maintained scalable data models to support business reporting needs.
    \item Built Power BI dashboards focused on performance tracking and business KPIs.
    \item Improved report performance by 40\% through optimization of DAX queries and data model structure.
    \item Streamlined data pipeline processes, reducing data refresh and processing time by 35\%.
    \item Conducted data quality checks and validation using SQL and Python to ensure accuracy.
\end{itemize}


\textbf{Working Student Data Analytics} \hfill Aug 2024 -- jun 2025\\
Siemens Healthineers \hfill \textit{Forcheim, Germany}
\begin{itemize}
    \item Developed and optimized Power BI dashboards for various business units to enable data-driven decision-making.
    \item Performed data extraction, transformation, and loading (ETL) using SQL and Python.
    \item Designed and orchestrated end-to-end data pipelines using Azure Data Factory for automated data ingestion and transformation workflows.
    \item Integrated Data Factory with Databricks and Azure SQL Database to streamline data flow and ensure scalability.
    \item Monitored and optimized pipeline performance, reducing data latency by 25\%.
\end{itemize}





\end{rSection}

%----------------------------------------------------------------------------------------
%	PROJECTS
%----------------------------------------------------------------------------------------
\begin{rSection}{PROJECTS}

\item \textbf{Data Analysis Dashboard:} Developed a Power BI dashboard to visualize trends and insights from cleaned data processed using Python (Pandas). Ensured data accuracy with preprocessing pipelines and deployed the dashboard to the cloud for real-time analytics. Enhanced reliability through error handling, reducing data processing time by 20\% 
(available on \href{https://github.com/Usama00004/SalesReport}{GitHub}).


\item \textbf{Real-Time Data Streaming:} Designed and implemented a real-time data streaming pipeline to process and analyze high-velocity data using Apache Kafka and Apache Flink. Data was ingested, transformed in real-time, and stored in PostgreSQL for further analysis, enabling low-latency insights and efficient data handling for large-scale systems.
(available on \href{https://github.com/Usama00004/StreamAnalysis}{GitHub}).

\item \textbf{Sentiment Analysis:} Developed a data pipeline integrating web scraping and sentiment analysis. Automated data extraction with BeautifulSoup and Selenium, reducing manual effort by 40\%. Cleaned and validated data with Pandas, stored in SQL, and deployed Scikit-learn models for real-time insights, improving processing efficiency by 25\% 
(available on \href{https://github.com/Usama00004/Twitter-Sentiment-Analysis}{GitHub}).

\begin{rSection}{Certifications}  
\begin{itemize}
    \item \textbf{Microsoft Power BI (PL-300):} Certified in transforming data into actionable insights (\href{https://github.com/Usama00004/Certifications/blob/main/Microsoft%20Pl-300%20Certified-.pdf}{view}).  
    \item \textbf{German Language B2.2:} Advanced proficiency in professional communication (\href{https://usama-tahir-00004.github.io/portfolio/files/B2_2.pdf}{view}).  
    \item \textbf{Microsoft Azure Fundamentals (AZ-900):} Understanding of cloud computing and Azure services.  
    \item \textbf{Google Data Analytics:} Skilled in data analysis and visualization.  
    \item \textbf{IBM Datastage:} Expertise in ETL processes and integration.  
\end{itemize}


\begin{rSection}{Publication}
\item \textbf{Hotspot-Aware Workload Scheduling and Server Placement for Heterogeneous Cloud Data Centers (Publication):} Researched and developed a novel approach for hotspot-aware workload scheduling and server placement in heterogeneous cloud data centers. Published in MDPI Energies Journal, the paper proposes innovative algorithms and methodologies to optimize resource utilization and minimize energy consumption in cloud environments 
(see publication on \href{https://www.mdpi.com/1996-1073/15/7/2541}{MDPI Energies})

\end{rSection}




\end{document}



