\documentclass[11pt,a4paper]{article}

%%%% Include Packages
\usepackage{fontspec}
\setmainfont{TeX Gyre Pagella} % Or any other modern font supporting ß
\usepackage[empty]{fullpage}
\usepackage[hidelinks]{hyperref}
\usepackage{xcolor}
\usepackage{ragged2e}
\usepackage{geometry}
\usepackage{setspace}

%%%% Set Margins
\geometry{top=1in, bottom=1in, left=0.5in, right=0.5in}

%%%% Define Colors
\definecolor{UI_blue}{RGB}{32, 64, 151}

%%%% Document Content
\begin{document}

\vspace{1cm} % Space between header and addresses

% Company name and addresses
\noindent
\begin{minipage}[t]{0.45\textwidth}
    Molkerei Gropper GmbH \& Co. KG\\
    Am Mühlberg 2\\
    86657 Bissingen\\
    Deutschland

\end{minipage}%
\hfill
% Sender name and addresses
\begin{minipage}[t]{0.45\textwidth}
    \raggedleft
    Usama Tahir \\
    Romerstadter str 3 \\
    86199 Augsburg\\
    Deutschland\\
    \vspace{1cm} % Adjust the space as needed
    \today
\end{minipage}

\vspace{1cm} % Space between addresses and subject line

% Subject line
\noindent
\textbf{Bewerbung als Data Warehouse Analyst}

\vspace{0.2cm} % Space between subject line and main content

% Main letter content
\justify
\setlength{\parindent}{0pt}
\setlength{\parskip}{12pt}

% Opening
\vspace{0.2cm}


Sehr geehrte Damen und Herren,
mit großem Interesse habe ich Ihre Stellenausschreibung für die Position im Bereich Data Warehouse, Datenmodellierung und ETL-Entwicklung gelesen. Als Data Analyst / Data Engineer mit fundierter Erfahrung in SQL-basierten Datenbanken, ETL-Prozessen, Datenmodellierung sowie Business-Intelligence-Lösungen bin ich überzeugt, dass ich Ihr Team wirkungsvoll unterstützen kann. Besonders reizt mich Ihre führende Marktposition im Bereich Milch- und Saftspezialitäten sowie Ihre klare Ausrichtung auf innovative Handelsmarkenprodukte in ganz Europa.

Während meiner Tätigkeiten bei Bosch, Siemens und Systems Limited habe ich Data-Warehouse-Architekturen aktiv mitgestaltet und weiterentwickelt. Dazu gehörte die Modellierung relationaler und multidimensionaler Datenmodelle, die Umsetzung qualitativ hochwertiger ETL-Strecken sowie die Optimierung bestehender Datenbanken und Transformationsprozesse. Mit T-SQL, SQL Server und Python habe ich robuste Datenpipelines entwickelt, die eine hohe Datenqualität, Konsistenz und Performance sicherstellen.

In meinen bisherigen Rollen war ich stets eng mit den Fachbereichen verbunden: von der strukturierten Anforderungsaufnahme über die Analyse bis hin zur fertigen Lösung. Dabei habe ich komplexe Geschäftsprozesse in skalierbare Datenmodelle übertragen, KPI-Strukturen aufgebaut und Power-BI-Reports für operative und strategische Entscheidungsprozesse entwickelt. Darüber hinaus habe ich Erfahrung in der Automatisierung von Ladeprozessen, der Betreuung von Datenbankservern und im 2nd-Level-Support für Reportinglösungen gesammelt.

Besonders spannend finde ich, dass Sie den gesamten DWH-Lebenszyklus abdecken und großen Wert auf Weiterentwicklung, Qualität und moderne Architekturen legen. Ich bringe eine schnelle Auffassungsgabe, hohe Eigenmotivation sowie Freude an teamorientierter Zusammenarbeit mit. Neue Technologien – insbesondere im Microsoft-Stack wie SSIS, SSAS sowie moderne SAP-Reporting-Tools – erlerne ich schnell und setze sie zielgerichtet ein.

Ich bin überzeugt, dass ich mit meiner Erfahrung in Datenintegration, Datenmodellierung, ETL-Prozessen und BI-Entwicklung einen wertvollen Beitrag für Ihr Unternehmen leisten kann. Sehr gerne würde ich dies in einem persönlichen Gespräch näher erläutern.

Vielen Dank für Ihre Zeit und die Berücksichtigung meiner Bewerbung. Ich freue mich auf Ihre Rückmeldung.


\vspace{0.5cm}

Mit freundlichen Grüßen,\\
Usama Tahir \\ 
(+49)-176-84973934 \\ 
\href{mailto:usamatahir00004@gmail.com}{usamatahir00004@gmail.com}\\ 
\href{https://usama00004.github.io/portfolio/}{https://usama00004.github.io/portfolio/}

\end{document}



\documentclass{resume}

\usepackage[left=0.4 in,top=0.2in,right=0.4 in,bottom=0.3in]{geometry}
\newcommand{\tab}[1]{\hspace{.2667\textwidth}\rlap{#1}} 
\newcommand{\itab}[1]{\hspace{0em}\rlap{#1}}
\name{Usama Tahir} 
\address{+49 17684973934 \\ Deutschland}
\address{\href{mailto:usamatahir00004@gmail.com}{E-Mail} \\ \href{http://www.linkedin.com/in/usamatahir-00004}{LinkedIn} \\ 
\href{https://github.com/Usama00004}{GitHub}} 

\begin{document}

%----------------------------------------------------------------------------------------
%	ZIEL
%----------------------------------------------------------------------------------------

\begin{rSection}{ZIEL}

Data-Warehouse- und BI-orientierter Data Engineer / Analyst mit Erfahrung in relationalen und multidimensionalen Datenmodellen, ETL-Entwicklung, SQL Server, Power BI und automatisierten Datenpipelines. Ich suche eine Position im Bereich Data Warehouse / Business Intelligence, um leistungsstarke DWH-Architekturen, robuste ETL-Prozesse und effiziente Reportinglösungen zu entwickeln und zu betreuen.

\end{rSection}

%----------------------------------------------------------------------------------------
%	AUSBILDUNG
%----------------------------------------------------------------------------------------

\begin{rSection}{AUSBILDUNG}

{\bf Master in Global Software Development}, Hochschule Fulda 
{\bf Bachelor in Informatik}, COMSATS Lahore 

\end{rSection}

%----------------------------------------------------------------------------------------
% FÄHIGKEITEN
%----------------------------------------------------------------------------------------

\begin{rSection}{FÄHIGKEITEN}

\textbf{Datenbanken \& DWH:} Microsoft SQL Server, T-SQL, Snowflake, Star-/Snowflake-Schema, multidimensionale Modelle, SSIS, SSAS \\
\textbf{ETL \& Datenintegration:} SSIS, Python (Pandas), API-Integration, Automatisierung, Datenmodellierung \\
\textbf{BI \& Reporting:} Power BI, DAX, Excel, KPI-Design, Datenvalidierung \\
\textbf{Tools \& Technologien:} Git, Docker, Linux, REST APIs \\
\textbf{Soft Skills:} Analytisches Denken, Kommunikation, Teamarbeit, Anforderungsanalyse \\
\textbf{Sprachen:} Deutsch (B1 CEFR), Englisch (C1 CEFR), Urdu, Punjabi, Hindi 

\end{rSection}

%----------------------------------------------------------------------------------------
%	BERUFSERFAHRUNG
%----------------------------------------------------------------------------------------

\begin{rSection}{BERUFSERFAHRUNG}

\textbf{Praktikant Data Analyst Digitalization \& Reporting} \hfill Sept 2025 -- laufend\\
\textbf{Bosch GmbH}, Reutlingen
\begin{itemize}
    \item Mitarbeit bei der Entwicklung und Nutzung von DWH-Datenmodellen zur Unterstützung von Produktions- und Logistikprozessen.
    \item Aufbau robuster Datenmodelle und multidimensionaler Power BI-Semantikschichten (DAX, Tabular).
    \item Automatisierung von ETL-Strecken über SQL und Python; Verbesserung der Datenqualität und Prozessstabilität.
    \item Analyse und Präzisierung neuer Anforderungen in enger Abstimmung mit Fachbereichen.
    \item Aktive Unterstützung im 2nd Level Reporting Support inkl. Fehleranalyse und Optimierungen.
\end{itemize}

\textbf{Werkstudent Data Analyst} \hfill Jan 2025 -- Aug 2025\\
\textbf{Siemens AG}, Forchheim
\begin{itemize}
    \item Mitwirkung bei der Erstellung und Erweiterung von DWH-Architekturen (Snowflake, SQL Server).
    \item Implementierung von ETL-Prozessen zur Integration heterogener Quellsysteme.
    \item Konzeption und Modellierung relationaler Datenmodelle für BI- und Controlling-Teams.
    \item Entwicklung leistungsstarker Power BI-Reports und KPI-Strukturen.
    \item Optimierung von SQL-Prozessen, Reduktion von Ladezeiten und Verbesserung der Datenqualität.
\end{itemize}

\textbf{Junior Data Analyst} \hfill Jan 2021 -- Juli 2022\\
\textbf{Systems Limited}, Lahore
\begin{itemize}
    \item Entwicklung und Betrieb von ETL-Pipelines (Python, SQL) zur Datenintegration aus Web-, API- und Systemquellen.
    \item Aufbau relationaler und multidimensionaler Datenmodelle für Reportingzwecke.
    \item Umsetzung automatisierter Reportinglösungen in Power BI für interne Stakeholder.
    \item Pflege und Optimierung von Datenbankservern sowie Sicherstellung hoher Datenqualität.
    \item Erstellung von Datenextraktionen aus ERP-nahen Quellen (SAP-ähnliche Systeme).
\end{itemize}

\end{rSection}

%----------------------------------------------------------------------------------------
%	PROJEKTE
%----------------------------------------------------------------------------------------

\begin{rSection}{PROJEKTE}

\item \textbf{DWH-Power-BI-Dashboard:} End-to-End Entwicklung eines analytischen Datenmodells mit ETL (Python/SQL) und Power BI, inkl. Validierungen, KPI-Modellierung und Bereinigungspipelines.

\item \textbf{Echtzeit-Datenpipeline:} Implementierung einer Streaming-Architektur (Kafka/Flink), Transformation und Speicherung in PostgreSQL für latenzarme Analysen.

\item \textbf{Sentiment-Analyse-Pipeline:} Automatisierte Datenerfassung (Selenium/BeautifulSoup), ETL mit Pandas, SQL-Speicherung und Predictive Analytics mittels Scikit-learn.

\end{rSection}

%----------------------------------------------------------------------------------------
%	VERÖFFENTLICHUNGEN
%----------------------------------------------------------------------------------------

\begin{rSection}{VERÖFFENTLICHUNGEN}
\item \textbf{Hotspot-Aware Workload Scheduling and Server Placement for Heterogeneous Cloud Data Centers} – veröffentlicht im MDPI Energies Journal.
\end{rSection}

\end{document}


