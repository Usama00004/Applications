\documentclass{resume}

\usepackage[left=0.4 in,top=0.2in,right=0.4 in,bottom=0.3in]{geometry}
\newcommand{\tab}[1]{\hspace{.2667\textwidth}\rlap{#1}} 
\newcommand{\itab}[1]{\hspace{0em}\rlap{#1}}

\name{Usama Tahir}
\address{+49 17684973934 \\ Deutschland}
\address{\href{mailto:usamatahir00004@gmail.com}{E-Mail} \\ 
\href{http://www.linkedin.com/in/usamatahir-00004}{LinkedIn} \\ 
\href{https://github.com/Usama00004}{GitHub}}

\begin{document}

%----------------------------------------------------------------------------------------
% PROFIL / ZIEL
%----------------------------------------------------------------------------------------

\begin{rSection}{PROFIL}

Business Intelligence Analyst mit Erfahrung in Datenanalyse, BI-Reporting, Datenmodellierung und ETL-Prozessen. Fundierte Kenntnisse in Power BI, SQL und Python zur Entwicklung von Planungs-, Forecast- und Reporting-Lösungen. Stark in der Übersetzung komplexer Daten in verständliche Insights zur Unterstützung datenbasierter Geschäftsentscheidungen.

\end{rSection}

%----------------------------------------------------------------------------------------
% AUSBILDUNG
%----------------------------------------------------------------------------------------

\begin{rSection}{AUSBILDUNG}
\textbf{M.Sc. Global Software Development} – Hochschule Fulda, Deutschland \\
\textbf{B.Sc. Informatik} – COMSATS Universität, Lahore   

\end{rSection}

%----------------------------------------------------------------------------------------
% KERNKOMPETENZEN
%----------------------------------------------------------------------------------------

\begin{rSection}{KERNKOMPETENZEN}

\textbf{Business Intelligence \& Analytics:} Power BI, KPI-Definition, Reporting, Dashboarding, Datenvisualisierung, Forecasting, Ad-hoc-Analysen\\
\textbf{Datenmanagement:} SQL, Datenmodellierung (Star Schema), Data Quality Checks, Validierung\\
\textbf{ETL / ELT:} Python (Pandas, NumPy), Web Scraping (Selenium, BeautifulSoup), Datenintegration\\
\textbf{Tools \& Technologien:} Power BI, Git, Excel, Jira, PostgreSQL\\
\textbf{Soft Skills:} Analytisches Denken, strukturierte Arbeitsweise, Stakeholder-Kommunikation, Teamarbeit\\
\textbf{Sprachen:} Deutsch, Englisch

\end{rSection}

%----------------------------------------------------------------------------------------
% BERUFSERFAHRUNG
%----------------------------------------------------------------------------------------
\begin{rSection}{BERUFSERFAHRUNG}

\textbf{Praktikant Data Analyst Digitalization \& Reporting} \hfill Sept 2025 -- laufend\\
\textbf{Bosch GmbH}, Reutlingen
\begin{itemize}
    \item Mitarbeit bei der Entwicklung und Nutzung von DWH-Datenmodellen zur Unterstützung von Produktions- und Logistikprozessen.
    \item Aufbau robuster Datenmodelle und multidimensionaler Power BI-Semantikschichten (DAX, Tabular).
    \item Automatisierung von ETL-Strecken über SQL und Python; Verbesserung der Datenqualität und Prozessstabilität.
    \item Analyse und Präzisierung neuer Anforderungen in enger Abstimmung mit Fachbereichen.
    \item Aktive Unterstützung im 2nd Level Reporting Support inkl. Fehleranalyse und Optimierungen.
\end{itemize}

\textbf{Werkstudent Data Analyst} \hfill Jan 2025 -- Aug 2025\\
\textbf{Siemens AG}, Forchheim
\begin{itemize}
    \item Mitwirkung bei der Erstellung und Erweiterung von DWH-Architekturen (Snowflake, SQL Server).
    \item Implementierung von ETL-Prozessen zur Integration heterogener Quellsysteme.
    \item Konzeption und Modellierung relationaler Datenmodelle für BI- und Controlling-Teams.
    \item Entwicklung leistungsstarker Power BI-Reports und KPI-Strukturen.
    \item Optimierung von SQL-Prozessen, Reduktion von Ladezeiten und Verbesserung der Datenqualität.
\end{itemize}

\textbf{Junior Data Analyst} \hfill Jan 2021 -- Juli 2022\\
\textbf{Systems Limited}, Lahore
\begin{itemize}
    \item Entwicklung und Betrieb von ETL-Pipelines (Python, SQL) zur Datenintegration aus Web-, API- und Systemquellen.
    \item Aufbau relationaler und multidimensionaler Datenmodelle für Reportingzwecke.
    \item Umsetzung automatisierter Reportinglösungen in Power BI für interne Stakeholder.
    \item Pflege und Optimierung von Datenbankservern sowie Sicherstellung hoher Datenqualität.
    \item Erstellung von Datenextraktionen aus ERP-nahen Quellen (SAP-ähnliche Systeme).
\end{itemize}

\end{rSection}

%----------------------------------------------------------------------------------------
% PROJEKTE
%----------------------------------------------------------------------------------------

\begin{rSection}{PROJEKTE}

\item \textbf{Power BI Sales \& Performance Dashboard} \\
Entwickelte ein interaktives Power BI-Dashboard zur Analyse von Umsatz-, Trend- und KPI-Daten. Implementierte Datenmodellierung und ETL-Pipelines mit Python (Pandas), wodurch die Reporting-Latenz um \textbf{20\%} reduziert wurde.(\href{https://github.com/Usama00004/SalesReport}{GitHub})

\item \textbf{Echtzeit-Datenanalyse Pipeline} \\
Entwarf und implementierte eine Echtzeit-Datenpipeline mit Apache Kafka und Flink zur Verarbeitung hochfrequenter Daten. Ermöglichte latenzarme Analysen für operative Entscheidungen und verbesserte die Verarbeitungseffizienz um \textbf{25\%}.(\href{https://github.com/Usama00004/StreamAnalysis}{GitHub})

\item \textbf{Sentiment-Analyse \& Datenautomatisierung} \\
Automatisierte Web-Datenerfassung und Analyse mittels Python, Selenium und SQL. Reduzierte manuellen Aufwand um \textbf{40\%} und verbesserte Datenqualität und Analysegeschwindigkeit signifikant.(\href{https://github.com/Usama00004/Twitter-Sentiment-Analysis}{GitHub})

\end{rSection}

\begin{rSection}{Zertifikate}  
\begin{itemize}

    \item \textbf{Microsoft Power BI Analyst (DP-700)} – \href{https://learn.microsoft.com/en-us/users/usamatahir-5344/credentials/9397793663d1b039?ref=https%3A%2F%2Fwww.linkedin.com%2F}{Zertifikat ansehen} 

    \item \textbf{Microsoft Power BI Analyst (DP-600)} – \href{https://learn.microsoft.com/en-us/users/usamatahir-5344/credentials/certification/fabric-analytics-engineer-associate?tab=credentials-tab}{Zertifikat ansehen} 
    
    \item \textbf{Microsoft Power BI Analyst (PL-300)} – \href{https://learn.microsoft.com/en-us/users/usamatahir-5344/credentials/f400769ffe6f66f8}{Zertifikat ansehen}  
    
    \item \textbf{Deutsch Sprachzertifikat B2.2} – \href{https://usama-tahir-00004.github.io/portfolio/files/B2_2.pdf}{Zertifikat ansehen}  
    
    \item \textbf{Google Datenanalyse} – \href{https://github.com/Usama00004/Certifications/blob/main/Google_Data_Analystics.pdf}{Zertifikat ansehen}  

\end{itemize}


%----------------------------------------------------------------------------------------
% VERÖFFENTLICHUNGEN
%----------------------------------------------------------------------------------------

\begin{rSection}{VERÖFFENTLICHUNGEN}

\item \textbf{Hotspot-Aware Workload Scheduling and Server Placement for Heterogeneous Cloud Data Centers} \\
MDPI Energies Journal. Entwicklung energieeffizienter Optimierungsmodelle zur Reduktion von Infrastrukturkosten und Ressourcenverbrauch in Cloud-Umgebungen. \\
(\href{https://www.mdpi.com/1996-1073/15/7/2541}{MDPI Energies})

\end{rSection}

\end{document}
